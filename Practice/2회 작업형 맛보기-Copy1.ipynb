{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1ed656",
   "metadata": {},
   "source": [
    "# 작업형 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490cc53",
   "metadata": {},
   "source": [
    "#### 01. mtcars2 데이터셋을 불러와 mpg 컬럼의 상위 10번째 값으로 상위 10개 값을 변환한 후 drat가 4 이상인 값에 대해 mpg의 평균을 구하여라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "538a4ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.671428571428574\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/기출복원/02회/mtcars2.csv')\n",
    "\n",
    "df2 = df[['mpg','drat']].copy()\n",
    "df2_rank = df2.sort_values('mpg', ascending=False).reset_index()[['mpg','drat']]\n",
    "\n",
    "mpg_val = df2_rank.loc[9]['mpg']\n",
    "\n",
    "df2_rank['mpg'][:9] = mpg_val\n",
    "\n",
    "# print(df2_rank)\n",
    "# print(mpg_val)\n",
    "\n",
    "result = df2_rank[df2_rank['drat'] >= 4]['mpg'].mean()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf7892a",
   "metadata": {},
   "source": [
    "#### 2. 앞의 데이터셋을 새로 불러와 첫 번째 행부터 순서대로 80%까지의 데이터를 훈련 데이터로 추출한 후 disp 컬럼의 결측값을 disp 컬럼의 중앙값으로 대체하고 대체 전 후의 disp 변수의 표준편차 값의 차이를 구하여라. (단, 차이는 빼는 순서와 관계없이 절댓값을 취하여 표시하고 소수점은 넷째 자리에서 반올림할 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a469120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.966\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/기출복원/02회/mtcars2.csv')\n",
    "# print(df.shape)\n",
    "\n",
    "portion = int(df.shape[0]*0.8)\n",
    "df2 = df[:portion]\n",
    "\n",
    "disp_med = df2['disp'].median()  # 중앙값 구하기\n",
    "\n",
    "before = df2['disp'].copy()  # 이전 데이터\n",
    "after = before.copy()\n",
    "\n",
    "after[df2['disp'].isna() == True] = disp_med  # 이후 데이터\n",
    "# print(before.isna().sum())\n",
    "# print(after.isna().sum())\n",
    "\n",
    "std_bef = before.std()\n",
    "std_aft = after.std()\n",
    "\n",
    "result = round(abs(std_aft - std_bef), 3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b00cb6",
   "metadata": {},
   "source": [
    "#### 3. gehan 데이터 셋을 불러와 time 컬럼에서 이상값의 합을 구하여라.(단, 이상값은 평균에서 1.5 표준편차 이상으로 벗어난 값으로 정의함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ecc5cd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/기출복원/02회/gehan.csv')\n",
    "\n",
    "# print(df.head())\n",
    "# print(df.shape)\n",
    "\n",
    "time = df['time'].copy()\n",
    "std_time = time.std()\n",
    "mean_time = time.mean()\n",
    "\n",
    "condition = (time >= mean_time+1.5*std_time) | (time <= mean_time-1.5*std_time)\n",
    "a = time[condition]\n",
    "result = a.sum()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18786863",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c73238",
   "metadata": {},
   "source": [
    "# 작업형2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f8c8cd",
   "metadata": {},
   "source": [
    "#### 1. 아래는 뇌졸중(stroke)에 대한 환자들의 임상적 변수에 관련한 데이터의 일부이다. 주어진 데이터를 이용하여 예측 모형을 만들고 아래에 따라 CSV 파일을 생성하시오. (단, 제출 전 두 개이상의 모형의 성능을 비교하여 가장 우수한 모형을 선정할 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "00211797",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv('data/기출복원/02회/stroke_X_train.csv')  # 4087\n",
    "y_train = pd.read_csv('data/기출복원/02회/stroke_y_train.csv')\n",
    "X_test = pd.read_csv('data/기출복원/02회/stroke_X_test.csv')  # 1022\n",
    "\n",
    "### EDA\n",
    "\n",
    "    # 범주 'gender','ever_married','work_type','Residence_type','smoking_status'\n",
    "    # 수치 'age','hypertension','heart_disease','avg_glucose_level','bmi'\n",
    "    \n",
    "# print(X_train.isna().sum(), '\\n\\n')\n",
    "# print(X_test.isna().sum())\n",
    "    # 결측치 'bmi' train(165) test(36)\n",
    "\n",
    "# 'id' -> 불필요. 제거\n",
    "X_train = X_train.drop(columns = 'id').copy()\n",
    "y_train = y_train.drop(columns = 'id').copy()\n",
    "ID = X_test.pop('id')\n",
    "\n",
    "# 'gender' -> 원-핫 인코딩\n",
    "# 'age' float -> int\n",
    "X_train['age'] = X_train['age'].astype('int64')\n",
    "X_test['age'] = X_test['age'].astype('int64')\n",
    "\n",
    "# 'hypertension' -> train - 0(3684) 1(403) / test - 0(927) 1(95) -> 인코딩 완료(범주)\n",
    "# 'heart_disease' -> train - 0(3863) 1(224) / test - 0(970) 1(52) -> 인코딩 완료(범주)\n",
    "# 'ever_married' -> 'Yes','No' -> 원-핫 인코딩\n",
    "# 'work_type' -> 'Private','Self-employed','children','Govt_job','Never_worked' -> 원-핫 인코딩\n",
    "# 'Residence_type' -> 'Urban','Rural' -> 원-핫 인코딩\n",
    "# 'smoking_status' -> 'never smoked','Unknown','formerly smoked','smokes' -> 'Unknown' 결측치로 판단\n",
    "    # 'Unknown'(1240) 너무 많음. 일부 제거할 시 데이터 손실 심각 -> 변수 제거\n",
    "X_train = X_train.drop(columns = 'smoking_status')\n",
    "X_test = X_test.drop(columns = 'smoking_status')\n",
    "\n",
    "# 'avg_glucose_level' -> mean(106.2) std(45.7) / max(271.7) min(55.2)\n",
    "# 'bmi' -> 결측치 처리\n",
    "train_bmi = X_train['bmi'].mean()\n",
    "X_train['bmi'] = X_train['bmi'].fillna(train_bmi).copy()\n",
    "\n",
    "test_bmi = X_test['bmi'].mean()\n",
    "X_test['bmi'] = X_test['bmi'].fillna(test_bmi).copy()\n",
    "\n",
    "### 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=2023)\n",
    "\n",
    "### 인코딩\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X_train_obj = X_train.select_dtypes('object').copy()\n",
    "X_val_obj = X_val.select_dtypes('object').copy()\n",
    "X_test_obj = X_test.select_dtypes('object').copy()\n",
    "\n",
    "oh = OneHotEncoder(sparse=False).fit(X_train_obj)\n",
    "\n",
    "X_train_oh = oh.transform(X_train_obj)\n",
    "X_val_oh = oh.transform(X_val_obj)\n",
    "X_test_oh = oh.transform(X_test_obj)\n",
    "\n",
    "### 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_num = X_train.select_dtypes(exclude = 'object').copy()\n",
    "X_val_num = X_val.select_dtypes(exclude = 'object').copy()\n",
    "X_test_num = X_test.select_dtypes(exclude = 'object').copy()\n",
    "\n",
    "scale = StandardScaler().fit(X_train_num)\n",
    "\n",
    "X_train_scale = scale.transform(X_train_num)\n",
    "X_val_scale = scale.transform(X_val_num)\n",
    "X_test_scale = scale.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e640990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23218489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b8309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e1331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860299e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87edd5c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idjs1\\.conda\\envs\\big_ana\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:52] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "### 1. 데이터 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv('data/기출복원/02회/stroke_X_train.csv')\n",
    "y_train = pd.read_csv('data/기출복원/02회/stroke_y_train.csv')\n",
    "X_test = pd.read_csv('data/기출복원/02회/stroke_X_test.csv')\n",
    "\n",
    "\n",
    "### 2. EDA - head(), info(), describe(), isnull().sum(), value_counts()\n",
    "\n",
    "        # 'id' 불필요\n",
    "        # 'age' 변수 조절\n",
    "        # 범주형 ['gender','ever_married','work_type','Residence_type','smoking_status']\n",
    "                #    2           2             5             2                4\n",
    "        # 'bmi' 결측치\n",
    "        # 'smoking_status'에서 'Unknown'은 결측치 아닌 결측치. 너무 많음 -> 'smoking_status' 제거\n",
    "\n",
    "### 3. 데이터 전처리\n",
    "# 1) 불필요 변수 제거\n",
    "X_train = X_train.drop('id', axis = 1)\n",
    "y_train = y_train.drop('id', axis = 1)\n",
    "test_id = X_test.pop('id')\n",
    "\n",
    "# 2) 결측치 처리\n",
    "mean_bmi = X_train['bmi'].mean()\n",
    "\n",
    "X_train['bmi'] = X_train['bmi'].fillna(mean_bmi)\n",
    "X_test['bmi'] = X_test['bmi'].fillna(mean_bmi)\n",
    "\n",
    "X_train = X_train.drop('smoking_status', axis = 1)\n",
    "X_test = X_test.drop('smoking_status', axis = 1)\n",
    "\n",
    "# 3) 범주형 변수 처리\n",
    "\n",
    "# 4) 수치형 변수 처리\n",
    "X_train['teen'] = pd.cut(X_train['age'], bins = list(range(0,100,10))).astype('object')\n",
    "X_test['teen'] = pd.cut(X_test['age'], bins = list(range(0,100,10))).astype('object')\n",
    "\n",
    "X_train = X_train.drop('age', axis = 1)\n",
    "X_test = X_test.drop('age', axis = 1)\n",
    "\n",
    "# 5) 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                  test_size = 0.3, \n",
    "                                                  random_state = 2022, \n",
    "                                                  stratify = y_train)\n",
    "\n",
    "\n",
    "# 6) 인코딩\n",
    "X_train_obj = X_train.select_dtypes('object').copy()\n",
    "X_val_obj = X_val.select_dtypes('object').copy()\n",
    "X_test_obj = X_test.select_dtypes('object').copy()\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse = False).fit(X_train_obj)\n",
    "\n",
    "X_train_oh = ohe.transform(X_train_obj)\n",
    "X_val_oh = ohe.transform(X_val_obj)\n",
    "X_test_oh = ohe.transform(X_test_obj)\n",
    "\n",
    "# 7) 스케일링\n",
    "X_train_num = X_train.select_dtypes(exclude = 'object').copy()\n",
    "X_val_num = X_val.select_dtypes(exclude = 'object').copy()\n",
    "X_test_num = X_test.select_dtypes(exclude = 'object').copy()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler().fit(X_train_num)\n",
    "\n",
    "X_train_scale = scale.transform(X_train_num)\n",
    "X_val_scale = scale.transform(X_val_num)\n",
    "X_test_scale = scale.transform(X_test_num)\n",
    "\n",
    "# 8) 데이터셋 준비\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.concatenate([X_train_oh, X_train_scale], axis = 1)\n",
    "X_val = np.concatenate([X_val_oh, X_val_scale], axis = 1)\n",
    "X_test = np.concatenate([X_test_oh, X_test_scale], axis = 1)\n",
    "\n",
    "y_train = y_train.values.flatten()\n",
    "y_val = y_val.values.flatten()\n",
    "\n",
    "\n",
    "### 4. 모델 학습 및 예측\n",
    "# 모델 학습\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "model_rf = rf.fit(X_train, y_train)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "model_xgb = xgb.fit(X_train, y_train)\n",
    "\n",
    "lgb = LGBMClassifier()\n",
    "model_lgb = lgb.fit(X_train, y_train)\n",
    "\n",
    "# 모델 검증\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_rf = model_rf.predict(X_val)\n",
    "pred_xgb = model_xgb.predict(X_val)\n",
    "pred_lgb = model_lgb.predict(X_val)\n",
    "\n",
    "acc_rf = accuracy_score(y_val, pred_rf)\n",
    "acc_xgb = accuracy_score(y_val, pred_xgb)\n",
    "acc_lgb = accuracy_score(y_val, pred_lgb)\n",
    "\n",
    "# 예측\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "\n",
    "### 5. 결과제출\n",
    "obj = {'id':test_id,\n",
    "       'stroke':y_pred}\n",
    "result = pd.DataFrame(obj)\n",
    "\n",
    "result.to_csv('12345.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd3016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
